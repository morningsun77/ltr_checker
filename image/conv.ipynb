{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06dea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/ipykernel_942650/1216664146.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\", line 870, in <module>\n",
      "    from . import _masked\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py\", line 420, in <module>\n",
      "    def sum(input: Tensor,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py\", line 223, in _apply_docstring_templates\n",
      "    example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n",
      "/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py:223: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "\n",
      "mid_res类型: <class 'list'>\n",
      "mid_res长度: 17\n",
      "\n",
      "前几个元素的信息:\n",
      "  [0] Tensor: shape=torch.Size([1, 1, 5, 50000]), device=cpu\n",
      "  [1] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      "  [2] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      "  [3] Tensor: shape=torch.Size([1, 32, 1, 4998]), device=cpu\n",
      "  [4] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      "  [5] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      "  [6] Tensor: shape=torch.Size([1, 64, 1, 331]), device=cpu\n",
      "  [7] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      "  [8] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      "  [9] Tensor: shape=torch.Size([1, 128, 1, 19]), device=cpu\n",
      "\n",
      "============================================================\n",
      "分析 Conv1\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 32, 1, 49981])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 32, 1, 49981)\n",
      "原始形状: (1, 32, 1, 49981)\n",
      "  squeeze后: (32, 49981)\n",
      "✅ 最终形状: (32, 49981)\n",
      "\n",
      "特征图形状: (32, 49981)\n",
      "LTR-RT原始位置: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RT特征位置: 2049 - 2950 (901 个位置)\n",
      "分辨率: 每个特征位置 ≈ 10 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "计算选择性指数...\n",
      "\n",
      "选择性统计:\n",
      "  LTR特异性通道 (SI > 0.2): 5 (15.6%)\n",
      "  背景特异性通道 (SI < -0.2): 7 (21.9%)\n",
      "  中性通道: 20 (62.5%)\n",
      "\n",
      "Top 5 判别通道:\n",
      "  1. Channel 13: SI = +2.800\n",
      "  2. Channel 4: SI = +0.778\n",
      "  3. Channel 1: SI = -0.543\n",
      "  4. Channel 14: SI = -0.509\n",
      "  5. Channel 18: SI = +0.458\n",
      "\n",
      "============================================================\n",
      "分析 Conv2\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 64, 1, 4979])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 64, 1, 4979)\n",
      "原始形状: (1, 64, 1, 4979)\n",
      "  squeeze后: (64, 4979)\n",
      "✅ 最终形状: (64, 4979)\n",
      "\n",
      "特征图形状: (64, 4979)\n",
      "LTR-RT原始位置: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RT特征位置: 136 - 196 (60 个位置)\n",
      "分辨率: 每个特征位置 ≈ 150 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "计算选择性指数...\n",
      "\n",
      "选择性统计:\n",
      "  LTR特异性通道 (SI > 0.2): 12 (18.8%)\n",
      "  背景特异性通道 (SI < -0.2): 36 (56.2%)\n",
      "  中性通道: 16 (25.0%)\n",
      "\n",
      "Top 5 判别通道:\n",
      "  1. Channel 33: SI = +132.287\n",
      "  2. Channel 3: SI = -37.297\n",
      "  3. Channel 11: SI = -34.313\n",
      "  4. Channel 24: SI = +24.373\n",
      "  5. Channel 8: SI = -12.256\n",
      "\n",
      "============================================================\n",
      "分析 Conv3\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 128, 1, 297])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 128, 1, 297)\n",
      "原始形状: (1, 128, 1, 297)\n",
      "  squeeze后: (128, 297)\n",
      "✅ 最终形状: (128, 297)\n",
      "\n",
      "特征图形状: (128, 297)\n",
      "LTR-RT原始位置: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RT特征位置: 9 - 13 (4 个位置)\n",
      "分辨率: 每个特征位置 ≈ 2250 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "计算选择性指数...\n",
      "\n",
      "选择性统计:\n",
      "  LTR特异性通道 (SI > 0.2): 22 (17.2%)\n",
      "  背景特异性通道 (SI < -0.2): 16 (12.5%)\n",
      "  中性通道: 90 (70.3%)\n",
      "\n",
      "Top 5 判别通道:\n",
      "  1. Channel 103: SI = +26.802\n",
      "  2. Channel 86: SI = +5.132\n",
      "  3. Channel 9: SI = +2.768\n",
      "  4. Channel 105: SI = +2.043\n",
      "  5. Channel 43: SI = +1.565\n",
      "\n",
      "✅ 成功分析了 3 个层\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "分析所有卷积层 (Conv1, Conv2, Conv3) 的LTR-RT特征\n",
    "比较不同分辨率下的特征表示\n",
    "修复版 - 处理所有可能的tensor转换问题\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"\n",
    "    使用tolist()方法安全转换tensor到numpy\n",
    "    这是最可靠的方法\n",
    "    \"\"\"\n",
    "    # 如果已经是numpy数组，直接返回\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        return tensor\n",
    "    \n",
    "    # 如果是Python列表，转为numpy\n",
    "    if isinstance(tensor, (list, tuple)):\n",
    "        return np.array(tensor)\n",
    "    \n",
    "    # 处理PyTorch tensor - 使用tolist()方法\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        # 先detach和cpu（如果需要）\n",
    "        if tensor.requires_grad:\n",
    "            tensor = tensor.detach()\n",
    "        if tensor.is_cuda:\n",
    "            tensor = tensor.cpu()\n",
    "        \n",
    "        # 使用tolist()转为Python列表，再转numpy\n",
    "        return np.array(tensor.tolist())\n",
    "    \n",
    "    # 其他情况\n",
    "    return np.array(tensor)\n",
    "\n",
    "# ==================== 配置 ====================\n",
    "LTR_START_ORIG = 20497\n",
    "LTR_END_ORIG = 29503\n",
    "\n",
    "# 各层的映射参数\n",
    "LAYER_CONFIG = {\n",
    "    'Conv1': {\n",
    "        'index': 1,\n",
    "        'stride': 10,\n",
    "        'channels': 32,\n",
    "        'name': 'Conv1 (after MaxPool 10x)'\n",
    "    },\n",
    "    'Conv2': {\n",
    "        'index': 4,\n",
    "        'stride': 150,  # 10 * 15\n",
    "        'channels': 64,\n",
    "        'name': 'Conv2 (after MaxPool 150x)'\n",
    "    },\n",
    "    'Conv3': {\n",
    "        'index': 7,\n",
    "        'stride': 2250,  # 10 * 15 * 15\n",
    "        'channels': 128,\n",
    "        'name': 'Conv3 (after MaxPool 2250x)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================== 加载数据 ====================\n",
    "print(\"加载数据...\")\n",
    "mid_res = torch.load('tensor_data.pt')\n",
    "\n",
    "# 检查数据结构\n",
    "print(f\"\\nmid_res类型: {type(mid_res)}\")\n",
    "print(f\"mid_res长度: {len(mid_res)}\")\n",
    "print(\"\\n前几个元素的信息:\")\n",
    "for i in range(min(10, len(mid_res))):\n",
    "    item = mid_res[i]\n",
    "    if isinstance(item, torch.Tensor):\n",
    "        print(f\"  [{i}] Tensor: shape={item.shape}, device={item.device}\")\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        print(f\"  [{i}] List/Tuple: 长度={len(item)}\")\n",
    "        if len(item) > 0 and isinstance(item[0], torch.Tensor):\n",
    "            print(f\"       第一个元素: shape={item[0].shape}, device={item[0].device}\")\n",
    "    else:\n",
    "        print(f\"  [{i}] 其他类型: {type(item)}\")\n",
    "\n",
    "# ==================== 分析函数 ====================\n",
    "def analyze_layer(layer_name, layer_config, mid_res):\n",
    "    \"\"\"分析单个卷积层\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"分析 {layer_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # 提取数据 - 处理可能的嵌套结构\n",
    "        layer_output = mid_res[layer_config['index']]\n",
    "        \n",
    "        print(f\"原始数据类型: {type(layer_output)}\")\n",
    "        \n",
    "        # 如果是列表或元组，取第一个元素\n",
    "        if isinstance(layer_output, (list, tuple)):\n",
    "            print(f\"  是序列类型，长度={len(layer_output)}\")\n",
    "            tensor = layer_output[0]\n",
    "        else:\n",
    "            tensor = layer_output\n",
    "        \n",
    "        print(f\"Tensor类型: {type(tensor)}\")\n",
    "        print(f\"Tensor形状: {tensor.shape}\")\n",
    "        print(f\"Tensor设备: {tensor.device}\")\n",
    "        print(f\"需要梯度: {tensor.requires_grad}\")\n",
    "        \n",
    "        # 转换为numpy\n",
    "        print(\"正在转换为numpy...\")\n",
    "        data = tensor_to_numpy(tensor)\n",
    "        print(f\"✅ 转换成功！numpy形状: {data.shape}\")\n",
    "        \n",
    "        # 关键：去除多余的维度 (1, 32, 1, 49981) -> (32, 49981)\n",
    "        print(f\"原始形状: {data.shape}\")\n",
    "        while data.ndim > 2:\n",
    "            # 找到大小为1的维度并squeeze\n",
    "            if 1 in data.shape:\n",
    "                data = np.squeeze(data)\n",
    "                print(f\"  squeeze后: {data.shape}\")\n",
    "            else:\n",
    "                # 如果没有大小为1的维度，可能需要reshape\n",
    "                # 假设格式是 (batch, channels, height, width)\n",
    "                # 取第一个batch\n",
    "                if data.shape[0] == 1:\n",
    "                    data = data[0]\n",
    "                    print(f\"  取第一个batch: {data.shape}\")\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        # 确保是2D (channels, positions)\n",
    "        if data.ndim == 3:\n",
    "            # 如果还是3D，可能是 (channels, 1, positions)\n",
    "            data = data.squeeze()\n",
    "            print(f\"  最终squeeze: {data.shape}\")\n",
    "        \n",
    "        print(f\"✅ 最终形状: {data.shape}\")\n",
    "        \n",
    "        stride = layer_config['stride']\n",
    "        \n",
    "        # 计算LTR-RT映射\n",
    "        ltr_start = LTR_START_ORIG // stride\n",
    "        ltr_end = LTR_END_ORIG // stride\n",
    "        ltr_width = ltr_end - ltr_start\n",
    "        \n",
    "        print(f\"\\n特征图形状: {data.shape}\")\n",
    "        print(f\"LTR-RT原始位置: {LTR_START_ORIG} - {LTR_END_ORIG} bp ({LTR_END_ORIG - LTR_START_ORIG} bp)\")\n",
    "        print(f\"LTR-RT特征位置: {ltr_start} - {ltr_end} ({ltr_width} 个位置)\")\n",
    "        print(f\"分辨率: 每个特征位置 ≈ {stride} bp\")\n",
    "        \n",
    "        # 归一化\n",
    "        print(\"正在归一化...\")\n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        data_norm = scaler.fit_transform(data.T).T\n",
    "        print(\"✅ 归一化完成\")\n",
    "        \n",
    "        # 计算选择性\n",
    "        print(\"计算选择性指数...\")\n",
    "        ltr_region = data[:, ltr_start:ltr_end]\n",
    "        bg_indices = list(range(0, ltr_start)) + list(range(ltr_end, data.shape[1]))\n",
    "        bg_region = data[:, bg_indices]\n",
    "        \n",
    "        ltr_activation = ltr_region.mean(axis=1)\n",
    "        bg_activation = bg_region.mean(axis=1)\n",
    "        selectivity = (ltr_activation - bg_activation) / (ltr_activation + bg_activation + 1e-8)\n",
    "        \n",
    "        # 统计\n",
    "        ltr_selective = np.sum(selectivity > 0.2)\n",
    "        bg_selective = np.sum(selectivity < -0.2)\n",
    "        neutral = np.sum(np.abs(selectivity) <= 0.2)\n",
    "        \n",
    "        print(f\"\\n选择性统计:\")\n",
    "        print(f\"  LTR特异性通道 (SI > 0.2): {ltr_selective} ({100*ltr_selective/len(selectivity):.1f}%)\")\n",
    "        print(f\"  背景特异性通道 (SI < -0.2): {bg_selective} ({100*bg_selective/len(selectivity):.1f}%)\")\n",
    "        print(f\"  中性通道: {neutral} ({100*neutral/len(selectivity):.1f}%)\")\n",
    "        \n",
    "        top_ch = np.argsort(np.abs(selectivity))[-5:][::-1]\n",
    "        print(f\"\\nTop 5 判别通道:\")\n",
    "        for i, ch in enumerate(top_ch, 1):\n",
    "            print(f\"  {i}. Channel {ch}: SI = {selectivity[ch]:+.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'data': data,\n",
    "            'data_norm': data_norm,\n",
    "            'ltr_start': ltr_start,\n",
    "            'ltr_end': ltr_end,\n",
    "            'selectivity': selectivity,\n",
    "            'top_channels': top_ch,\n",
    "            'stats': {\n",
    "                'ltr_selective': ltr_selective,\n",
    "                'bg_selective': bg_selective,\n",
    "                'neutral': neutral\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 错误: {e}\")\n",
    "        print(f\"错误类型: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ==================== 分析所有层 ====================\n",
    "results = {}\n",
    "for layer_name, config in LAYER_CONFIG.items():\n",
    "    result = analyze_layer(layer_name, config, mid_res)\n",
    "    if result is not None:\n",
    "        results[layer_name] = result\n",
    "    else:\n",
    "        print(f\"\\n⚠️ {layer_name} 分析失败，跳过\")\n",
    "\n",
    "# 检查是否有成功的结果\n",
    "if len(results) == 0:\n",
    "    print(\"\\n❌ 所有层都分析失败！\")\n",
    "    print(\"请检查数据格式和索引是否正确\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\n✅ 成功分析了 {len(results)} 个层\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e115a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "生成对比可视化...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 36890 (\\N{CJK UNIFIED IDEOGRAPH-901A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 36947 (\\N{CJK UNIFIED IDEOGRAPH-9053}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 24449 (\\N{CJK UNIFIED IDEOGRAPH-5F81}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 36873 (\\N{CJK UNIFIED IDEOGRAPH-9009}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 25321 (\\N{CJK UNIFIED IDEOGRAPH-62E9}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 25351 (\\N{CJK UNIFIED IDEOGRAPH-6307}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 28608 (\\N{CJK UNIFIED IDEOGRAPH-6FC0}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 27963 (\\N{CJK UNIFIED IDEOGRAPH-6D3B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 21028 (\\N{CJK UNIFIED IDEOGRAPH-5224}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:54: UserWarning: Glyph 21035 (\\N{CJK UNIFIED IDEOGRAPH-522B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 36890 (\\N{CJK UNIFIED IDEOGRAPH-901A}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 36947 (\\N{CJK UNIFIED IDEOGRAPH-9053}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 24449 (\\N{CJK UNIFIED IDEOGRAPH-5F81}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 36873 (\\N{CJK UNIFIED IDEOGRAPH-9009}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 25321 (\\N{CJK UNIFIED IDEOGRAPH-62E9}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 25351 (\\N{CJK UNIFIED IDEOGRAPH-6307}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 28608 (\\N{CJK UNIFIED IDEOGRAPH-6FC0}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 27963 (\\N{CJK UNIFIED IDEOGRAPH-6D3B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 21028 (\\N{CJK UNIFIED IDEOGRAPH-5224}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2289553760.py:55: UserWarning: Glyph 21035 (\\N{CJK UNIFIED IDEOGRAPH-522B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 对比图已保存: all_layers_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# ==================== 创建对比可视化 ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"生成对比可视化...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 为每层创建3个子图 (热图 + 选择性 + top通道)\n",
    "row = 0\n",
    "for layer_name, result in results.items():\n",
    "    # 热图\n",
    "    ax_heatmap = plt.subplot(len(results), 3, row*3 + 1)\n",
    "    im = ax_heatmap.imshow(result['data_norm'], aspect='auto', cmap='RdYlBu_r',\n",
    "                           interpolation='nearest', vmin=-2, vmax=2)\n",
    "    ax_heatmap.axvline(result['ltr_start'], color='lime', linewidth=2, linestyle='--')\n",
    "    ax_heatmap.axvline(result['ltr_end'], color='lime', linewidth=2, linestyle='--')\n",
    "    ax_heatmap.axvspan(result['ltr_start'], result['ltr_end'], alpha=0.2, color='yellow')\n",
    "    ax_heatmap.set_title(f\"{LAYER_CONFIG[layer_name]['name']}\\n特征图\", \n",
    "                         fontsize=11, fontweight='bold')\n",
    "    ax_heatmap.set_xlabel('位置')\n",
    "    ax_heatmap.set_ylabel('通道')\n",
    "    plt.colorbar(im, ax=ax_heatmap)\n",
    "    \n",
    "    # 选择性指数\n",
    "    ax_si = plt.subplot(len(results), 3, row*3 + 2)\n",
    "    selectivity = result['selectivity']\n",
    "    colors = ['red' if s > 0.2 else 'blue' if s < -0.2 else 'lightgray' for s in selectivity]\n",
    "    ax_si.bar(range(len(selectivity)), selectivity, color=colors, alpha=0.7, width=1.0)\n",
    "    ax_si.axhline(0, color='black', linewidth=1)\n",
    "    ax_si.axhline(0.2, color='red', linestyle='--', linewidth=1)\n",
    "    ax_si.axhline(-0.2, color='blue', linestyle='--', linewidth=1)\n",
    "    ax_si.set_title(f\"选择性指数\\n(LTR:{result['stats']['ltr_selective']}, BG:{result['stats']['bg_selective']})\", \n",
    "                    fontsize=11, fontweight='bold')\n",
    "    ax_si.set_xlabel('通道')\n",
    "    ax_si.set_ylabel('SI')\n",
    "    ax_si.set_ylim(-1, 1)\n",
    "    ax_si.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top通道激活\n",
    "    ax_top = plt.subplot(len(results), 3, row*3 + 3)\n",
    "    for ch in result['top_channels']:\n",
    "        ax_top.plot(result['data'][ch, :], label=f'Ch {ch}', linewidth=1.5, alpha=0.7)\n",
    "    ax_top.axvspan(result['ltr_start'], result['ltr_end'], alpha=0.2, color='yellow')\n",
    "    ax_top.axvline(result['ltr_start'], color='lime', linewidth=2, linestyle='--')\n",
    "    ax_top.axvline(result['ltr_end'], color='lime', linewidth=2, linestyle='--')\n",
    "    ax_top.set_title(f\"Top 5 判别通道\", fontsize=11, fontweight='bold')\n",
    "    ax_top.set_xlabel('位置')\n",
    "    ax_top.set_ylabel('激活值')\n",
    "    ax_top.legend(fontsize=7, loc='best')\n",
    "    ax_top.grid(True, alpha=0.3)\n",
    "    \n",
    "    row += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_layers_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ 对比图已保存: all_layers_comparison.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9090ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "汇总统计\n",
      "============================================================\n",
      "\n",
      "层名称        分辨率          LTR宽度      LTR特异      背景特异       最高SI      \n",
      "----------------------------------------------------------------------\n",
      "Conv1        10 bp/pos    901 pos       5 ch        7 ch     2.800\n",
      "Conv2       150 bp/pos     60 pos      12 ch       36 ch     132.287\n",
      "Conv3      2250 bp/pos      4 pos      22 ch       16 ch     26.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 21367 (\\N{CJK UNIFIED IDEOGRAPH-5377}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 31215 (\\N{CJK UNIFIED IDEOGRAPH-79EF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 23618 (\\N{CJK UNIFIED IDEOGRAPH-5C42}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 36890 (\\N{CJK UNIFIED IDEOGRAPH-901A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 36947 (\\N{CJK UNIFIED IDEOGRAPH-9053}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 36873 (\\N{CJK UNIFIED IDEOGRAPH-9009}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 25321 (\\N{CJK UNIFIED IDEOGRAPH-62E9}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 24322 (\\N{CJK UNIFIED IDEOGRAPH-5F02}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 32972 (\\N{CJK UNIFIED IDEOGRAPH-80CC}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 26223 (\\N{CJK UNIFIED IDEOGRAPH-666F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 23485 (\\N{CJK UNIFIED IDEOGRAPH-5BBD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 24449 (\\N{CJK UNIFIED IDEOGRAPH-5F81}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 38477 (\\N{CJK UNIFIED IDEOGRAPH-964D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 20493 (\\N{CJK UNIFIED IDEOGRAPH-500D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 36776 (\\N{CJK UNIFIED IDEOGRAPH-8FA8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:63: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 36890 (\\N{CJK UNIFIED IDEOGRAPH-901A}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 36947 (\\N{CJK UNIFIED IDEOGRAPH-9053}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 23618 (\\N{CJK UNIFIED IDEOGRAPH-5C42}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 36873 (\\N{CJK UNIFIED IDEOGRAPH-9009}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 25321 (\\N{CJK UNIFIED IDEOGRAPH-62E9}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 21367 (\\N{CJK UNIFIED IDEOGRAPH-5377}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 31215 (\\N{CJK UNIFIED IDEOGRAPH-79EF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 24322 (\\N{CJK UNIFIED IDEOGRAPH-5F02}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 32972 (\\N{CJK UNIFIED IDEOGRAPH-80CC}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 26223 (\\N{CJK UNIFIED IDEOGRAPH-666F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 38477 (\\N{CJK UNIFIED IDEOGRAPH-964D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 20493 (\\N{CJK UNIFIED IDEOGRAPH-500D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 23485 (\\N{CJK UNIFIED IDEOGRAPH-5BBD}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 24449 (\\N{CJK UNIFIED IDEOGRAPH-5F81}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 36776 (\\N{CJK UNIFIED IDEOGRAPH-8FA8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
      "/scratch/ipykernel_942650/2572983950.py:64: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 统计图已保存: layers_statistics.png\n"
     ]
    }
   ],
   "source": [
    "# ==================== 生成汇总表格 ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"汇总统计\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n{'层名称':<10} {'分辨率':<12} {'LTR宽度':<10} {'LTR特异':<10} {'背景特异':<10} {'最高SI':<10}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for layer_name, result in results.items():\n",
    "    config = LAYER_CONFIG[layer_name]\n",
    "    max_si = np.max(np.abs(result['selectivity']))\n",
    "    ltr_width = result['ltr_end'] - result['ltr_start']\n",
    "    \n",
    "    print(f\"{layer_name:<10} {config['stride']:>4} bp/pos   {ltr_width:>4} pos    \"\n",
    "          f\"{result['stats']['ltr_selective']:>4} ch     \"\n",
    "          f\"{result['stats']['bg_selective']:>4} ch     \"\n",
    "          f\"{max_si:>5.3f}\")\n",
    "\n",
    "# ==================== 创建统计图 ====================\n",
    "if len(results) > 1:\n",
    "    fig2, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 左图: 各层的LTR特异性通道数\n",
    "    ax1 = axes[0]\n",
    "    layer_names = list(results.keys())\n",
    "    ltr_counts = [results[name]['stats']['ltr_selective'] for name in layer_names]\n",
    "    bg_counts = [results[name]['stats']['bg_selective'] for name in layer_names]\n",
    "    \n",
    "    x = np.arange(len(layer_names))\n",
    "    width = 0.35\n",
    "    ax1.bar(x - width/2, ltr_counts, width, label='LTR特异性', color='crimson', alpha=0.8)\n",
    "    ax1.bar(x + width/2, bg_counts, width, label='背景特异性', color='steelblue', alpha=0.8)\n",
    "    ax1.set_xlabel('卷积层', fontsize=12)\n",
    "    ax1.set_ylabel('通道数', fontsize=12)\n",
    "    ax1.set_title('各层选择性通道分布', fontsize=13, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(layer_names)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 右图: LTR-RT特征空间宽度\n",
    "    ax2 = axes[1]\n",
    "    ltr_widths = [results[name]['ltr_end'] - results[name]['ltr_start'] for name in layer_names]\n",
    "    strides = [LAYER_CONFIG[name]['stride'] for name in layer_names]\n",
    "    \n",
    "    ax2_twin = ax2.twinx()\n",
    "    ax2.bar(x, ltr_widths, alpha=0.7, color='orange', label='LTR宽度(位置数)')\n",
    "    ax2_twin.plot(x, strides, 'ro-', linewidth=2, markersize=8, label='降维倍数')\n",
    "    \n",
    "    ax2.set_xlabel('卷积层', fontsize=12)\n",
    "    ax2.set_ylabel('LTR-RT宽度 (特征位置数)', fontsize=12, color='orange')\n",
    "    ax2_twin.set_ylabel('降维倍数 (bp/位置)', fontsize=12, color='red')\n",
    "    ax2.set_title('LTR-RT分辨率变化', fontsize=13, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(layer_names)\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    ax2_twin.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2_twin.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('layers_statistics.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✅ 统计图已保存: layers_statistics.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc30bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 结论与建议\n",
      "============================================================\n",
      "\n",
      "✅ 推荐分析层: Conv3\n",
      "   原因: 最多的LTR特异性通道 (22 个)\n",
      "\n",
      "💡 建议:\n",
      "   - Conv3有最多的选择性通道，说明深层特征最判别\n",
      "   - 模型成功学习到了高度抽象的LTR-RT表示\n",
      "   - 这些深层特征可能对应整体的转座子结构\n",
      "\n",
      "============================================================\n",
      "✅ 分析完成!\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== 结论 ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎯 结论与建议\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 找出最佳分析层\n",
    "best_layer = max(results.items(), \n",
    "                 key=lambda x: x[1]['stats']['ltr_selective'])\n",
    "print(f\"\\n✅ 推荐分析层: {best_layer[0]}\")\n",
    "print(f\"   原因: 最多的LTR特异性通道 ({best_layer[1]['stats']['ltr_selective']} 个)\")\n",
    "\n",
    "# 给出建议\n",
    "if best_layer[0] == 'Conv1':\n",
    "    print(\"\\n💡 建议:\")\n",
    "    print(\"   - Conv1有最多的选择性通道，说明浅层特征最明显\")\n",
    "    print(\"   - 可能模型在深层过度平滑了特征\")\n",
    "    print(\"   - 建议可视化Conv1的卷积核，看学到了什么局部模式\")\n",
    "    \n",
    "elif best_layer[0] == 'Conv2':\n",
    "    print(\"\\n💡 建议:\")\n",
    "    print(\"   - Conv2平衡了分辨率和抽象程度\")\n",
    "    print(\"   - 这一层可能捕获了中等尺度的LTR-RT结构特征\")\n",
    "    print(\"   - 建议重点分析Conv2的特征\")\n",
    "    \n",
    "else:  # Conv3\n",
    "    print(\"\\n💡 建议:\")\n",
    "    print(\"   - Conv3有最多的选择性通道，说明深层特征最判别\")\n",
    "    print(\"   - 模型成功学习到了高度抽象的LTR-RT表示\")\n",
    "    print(\"   - 这些深层特征可能对应整体的转座子结构\")\n",
    "\n",
    "# 检查是否有问题\n",
    "total_selective = sum(r['stats']['ltr_selective'] for r in results.values())\n",
    "if total_selective < 15:\n",
    "    print(\"\\n⚠️  警告: 选择性通道总数较少\")\n",
    "    print(\"   可能的原因:\")\n",
    "    print(\"   - 模型训练不足\")\n",
    "    print(\"   - 数据标签噪声\")\n",
    "    print(\"   - LTR-RT特征不够显著\")\n",
    "    print(\"   建议: 检查模型训练过程和数据质量\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"✅ 分析完成!\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52edc831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "生成无标亮的纯净热图...\n",
      "============================================================\n",
      "\n",
      "✅ Conv1 纯净热图已保存: Conv1_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 32 channels × 49981 positions\n",
      "\n",
      "✅ Conv2 纯净热图已保存: Conv2_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 64 channels × 4979 positions\n",
      "\n",
      "✅ Conv3 纯净热图已保存: Conv3_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 128 channels × 297 positions\n",
      "\n",
      "============================================================\n",
      "✅ 完成！所有纯净热图已生成\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== 生成无标亮的纯净热图 ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"生成无标亮的纯净热图...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for layer_name, result in results.items():\n",
    "    data_width = result['data'].shape[1]\n",
    "    data_channels = result['data'].shape[0]\n",
    "    \n",
    "    # 统一图片尺寸 - 所有图都方正\n",
    "    fig_width = 12\n",
    "    fig_height = 10\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # 绘制热图\n",
    "    im = ax.imshow(result['data_norm'], aspect='auto', cmap='RdYlBu_r',\n",
    "                   interpolation='nearest', vmin=-2, vmax=2)\n",
    "    \n",
    "    # 计算层描述\n",
    "    if layer_name == 'Conv1':\n",
    "        layer_desc = 'Conv1'\n",
    "    elif layer_name == 'Conv2':\n",
    "        layer_desc = 'Conv2'\n",
    "    else:\n",
    "        layer_desc = 'Conv3'\n",
    "    \n",
    "    # 标题\n",
    "    ax.set_title(f\"{layer_desc}\\n\"\n",
    "                 f\"Shape: {data_channels} channels × {data_width} positions\",\n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel('Feature Map Position', fontsize=11)\n",
    "    ax.set_ylabel('Channel', fontsize=11)\n",
    "    \n",
    "    # 颜色条\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Normalized Activation', rotation=270, labelpad=20, fontsize=10)\n",
    "    \n",
    "    # 网格 - 根据通道数调整\n",
    "    if data_channels <= 64:\n",
    "        ytick_step = max(1, data_channels // 16)\n",
    "    else:\n",
    "        ytick_step = max(1, data_channels // 20)\n",
    "    ax.set_yticks(np.arange(0, data_channels, ytick_step))\n",
    "    ax.grid(True, alpha=0.2, axis='y', linestyle=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存\n",
    "    filename = f'{layer_name}_heatmap_clean.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ {layer_name} 纯净热图已保存: {filename}\")\n",
    "    print(f\"   - 图片尺寸: {fig_width}×{fig_height} inches\")\n",
    "    print(f\"   - 特征图: {data_channels} channels × {data_width} positions\\n\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"✅ 完成！所有纯净热图已生成\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
