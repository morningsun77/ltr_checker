{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æ•°æ®...\n",
      "\n",
      "mid_resç±»å‹: <class 'list'>\n",
      "mid_resé•¿åº¦: 17\n",
      "\n",
      "å‰å‡ ä¸ªå…ƒç´ çš„ä¿¡æ¯:\n",
      " [0] Tensor: shape=torch.Size([1, 1, 5, 50000]), device=cpu\n",
      " [1] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      " [2] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      " [3] Tensor: shape=torch.Size([1, 32, 1, 4998]), device=cpu\n",
      " [4] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      " [5] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      " [6] Tensor: shape=torch.Size([1, 64, 1, 331]), device=cpu\n",
      " [7] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      " [8] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      " [9] Tensor: shape=torch.Size([1, 128, 1, 19]), device=cpu\n",
      "\n",
      "============================================================\n",
      "åˆ†æ Conv1\n",
      "============================================================\n",
      "åŸå§‹æ•°æ®ç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorå½¢çŠ¶: torch.Size([1, 32, 1, 49981])\n",
      "Tensorè®¾å¤‡: cpu\n",
      "éœ€è¦æ¢¯åº¦: False\n",
      "æ­£åœ¨è½¬æ¢ä¸ºnumpy...\n",
      "âœ… è½¬æ¢æˆåŠŸï¼numpyå½¢çŠ¶: (1, 32, 1, 49981)\n",
      "åŸå§‹å½¢çŠ¶: (1, 32, 1, 49981)\n",
      " squeezeå: (32, 49981)\n",
      "âœ… æœ€ç»ˆå½¢çŠ¶: (32, 49981)\n",
      "\n",
      "ç‰¹å¾å›¾å½¢çŠ¶: (32, 49981)\n",
      "LTR-RTåŸå§‹ä½ç½®: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RTç‰¹å¾ä½ç½®: 2049 - 2950 (901 ä¸ªä½ç½®)\n",
      "åˆ†è¾¨ç‡: æ¯ä¸ªç‰¹å¾ä½ç½® â‰ˆ 10 bp\n",
      "æ­£åœ¨å½’ä¸€åŒ–...\n",
      "âœ… å½’ä¸€åŒ–å®Œæˆ\n",
      "è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°...\n",
      "\n",
      "é€‰æ‹©æ€§ç»Ÿè®¡:\n",
      " LTRç‰¹å¼‚æ€§é€šé“ (SI > 0.2): 5 (15.6%)\n",
      " èƒŒæ™¯ç‰¹å¼‚æ€§é€šé“ (SI < -0.2): 7 (21.9%)\n",
      " ä¸­æ€§é€šé“: 20 (62.5%)\n",
      "\n",
      "Top 5 åˆ¤åˆ«é€šé“:\n",
      " 1. Channel 13: SI = +2.800\n",
      " 2. Channel 4: SI = +0.778\n",
      " 3. Channel 1: SI = -0.543\n",
      " 4. Channel 14: SI = -0.509\n",
      " 5. Channel 18: SI = +0.458\n",
      "\n",
      "============================================================\n",
      "åˆ†æ Conv2\n",
      "============================================================\n",
      "åŸå§‹æ•°æ®ç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorå½¢çŠ¶: torch.Size([1, 64, 1, 4979])\n",
      "Tensorè®¾å¤‡: cpu\n",
      "éœ€è¦æ¢¯åº¦: False\n",
      "æ­£åœ¨è½¬æ¢ä¸ºnumpy...\n",
      "âœ… è½¬æ¢æˆåŠŸï¼numpyå½¢çŠ¶: (1, 64, 1, 4979)\n",
      "åŸå§‹å½¢çŠ¶: (1, 64, 1, 4979)\n",
      " squeezeå: (64, 4979)\n",
      "âœ… æœ€ç»ˆå½¢çŠ¶: (64, 4979)\n",
      "\n",
      "ç‰¹å¾å›¾å½¢çŠ¶: (64, 4979)\n",
      "LTR-RTåŸå§‹ä½ç½®: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RTç‰¹å¾ä½ç½®: 136 - 196 (60 ä¸ªä½ç½®)\n",
      "åˆ†è¾¨ç‡: æ¯ä¸ªç‰¹å¾ä½ç½® â‰ˆ 150 bp\n",
      "æ­£åœ¨å½’ä¸€åŒ–...\n",
      "âœ… å½’ä¸€åŒ–å®Œæˆ\n",
      "è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°...\n",
      "\n",
      "é€‰æ‹©æ€§ç»Ÿè®¡:\n",
      " LTRç‰¹å¼‚æ€§é€šé“ (SI > 0.2): 12 (18.8%)\n",
      " èƒŒæ™¯ç‰¹å¼‚æ€§é€šé“ (SI < -0.2): 36 (56.2%)\n",
      " ä¸­æ€§é€šé“: 16 (25.0%)\n",
      "\n",
      "Top 5 åˆ¤åˆ«é€šé“:\n",
      " 1. Channel 33: SI = +132.287\n",
      " 2. Channel 3: SI = -37.297\n",
      " 3. Channel 11: SI = -34.313\n",
      " 4. Channel 24: SI = +24.373\n",
      " 5. Channel 8: SI = -12.256\n",
      "\n",
      "============================================================\n",
      "åˆ†æ Conv3\n",
      "============================================================\n",
      "åŸå§‹æ•°æ®ç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorç±»å‹: <class 'torch.Tensor'>\n",
      "Tensorå½¢çŠ¶: torch.Size([1, 128, 1, 297])\n",
      "Tensorè®¾å¤‡: cpu\n",
      "éœ€è¦æ¢¯åº¦: False\n",
      "æ­£åœ¨è½¬æ¢ä¸ºnumpy...\n",
      "âœ… è½¬æ¢æˆåŠŸï¼numpyå½¢çŠ¶: (1, 128, 1, 297)\n",
      "åŸå§‹å½¢çŠ¶: (1, 128, 1, 297)\n",
      " squeezeå: (128, 297)\n",
      "âœ… æœ€ç»ˆå½¢çŠ¶: (128, 297)\n",
      "\n",
      "ç‰¹å¾å›¾å½¢çŠ¶: (128, 297)\n",
      "LTR-RTåŸå§‹ä½ç½®: 20497 - 29503 bp (9006 bp)\n",
      "LTR-RTç‰¹å¾ä½ç½®: 9 - 13 (4 ä¸ªä½ç½®)\n",
      "åˆ†è¾¨ç‡: æ¯ä¸ªç‰¹å¾ä½ç½® â‰ˆ 2250 bp\n",
      "æ­£åœ¨å½’ä¸€åŒ–...\n",
      "âœ… å½’ä¸€åŒ–å®Œæˆ\n",
      "è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°...\n",
      "\n",
      "é€‰æ‹©æ€§ç»Ÿè®¡:\n",
      " LTRç‰¹å¼‚æ€§é€šé“ (SI > 0.2): 22 (17.2%)\n",
      " èƒŒæ™¯ç‰¹å¼‚æ€§é€šé“ (SI < -0.2): 16 (12.5%)\n",
      " ä¸­æ€§é€šé“: 90 (70.3%)\n",
      "\n",
      "Top 5 åˆ¤åˆ«é€šé“:\n",
      " 1. Channel 103: SI = +26.802\n",
      " 2. Channel 86: SI = +5.132\n",
      " 3. Channel 9: SI = +2.768\n",
      " 4. Channel 105: SI = +2.043\n",
      " 5. Channel 43: SI = +1.565\n",
      "\n",
      "âœ… æˆåŠŸåˆ†æäº† 3 ä¸ªå±‚\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "åˆ†ææ‰€æœ‰å·ç§¯å±‚ (Conv1, Conv2, Conv3) çš„LTR-RTç‰¹å¾\n",
    "æ¯”è¾ƒä¸åŒåˆ†è¾¨ç‡ä¸‹çš„ç‰¹å¾è¡¨ç¤º\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches  # æ–°å¢å¯¼å…¥\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨tolist()æ–¹æ³•å®‰å…¨è½¬æ¢tensoråˆ°numpy\n",
    "    \"\"\"\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        return tensor\n",
    "    if isinstance(tensor, (list, tuple)):\n",
    "        return np.array(tensor)\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        if tensor.requires_grad:\n",
    "            tensor = tensor.detach()\n",
    "        if tensor.is_cuda:\n",
    "            tensor = tensor.cpu()\n",
    "        return np.array(tensor.tolist())\n",
    "    return np.array(tensor)\n",
    "\n",
    "# ==================== é…ç½® ====================\n",
    "LTR_START_ORIG = 20497\n",
    "LTR_END_ORIG = 29503\n",
    "\n",
    "# å„å±‚çš„æ˜ å°„å‚æ•°\n",
    "LAYER_CONFIG = {\n",
    "    'Conv1': {\n",
    "        'index': 1,\n",
    "        'stride': 10,\n",
    "        'channels': 32,\n",
    "        'name': 'Conv1 (after MaxPool 10x)'\n",
    "    },\n",
    "    'Conv2': {\n",
    "        'index': 4,\n",
    "        'stride': 150,\n",
    "        'channels': 64,\n",
    "        'name': 'Conv2 (after MaxPool 150x)'\n",
    "    },\n",
    "    'Conv3': {\n",
    "        'index': 7,\n",
    "        'stride': 2250,\n",
    "        'channels': 128,\n",
    "        'name': 'Conv3 (after MaxPool 2250x)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# å®šä¹‰å„å±‚çš„ LTR-RT åŒºé—´\n",
    "LTR_INTERVALS = {\n",
    "    'Conv1': {\n",
    "        'all_ltr': (20497, 29484)\n",
    "    },\n",
    "    'Conv2': {\n",
    "        'all_ltr': (2050, 2929)\n",
    "    },\n",
    "    'Conv3': {\n",
    "        'all_ltr': (137, 160)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================== åŠ è½½æ•°æ® ====================\n",
    "print(\"åŠ è½½æ•°æ®...\")\n",
    "mid_res = torch.load('tensor_data.pt')\n",
    "\n",
    "print(f\"\\nmid_resç±»å‹: {type(mid_res)}\")\n",
    "print(f\"mid_resé•¿åº¦: {len(mid_res)}\")\n",
    "print(\"\\nå‰å‡ ä¸ªå…ƒç´ çš„ä¿¡æ¯:\")\n",
    "for i in range(min(10, len(mid_res))):\n",
    "    item = mid_res[i]\n",
    "    if isinstance(item, torch.Tensor):\n",
    "        print(f\" [{i}] Tensor: shape={item.shape}, device={item.device}\")\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        print(f\" [{i}] List/Tuple: é•¿åº¦={len(item)}\")\n",
    "        if len(item) > 0 and isinstance(item[0], torch.Tensor):\n",
    "            print(f\"     ç¬¬ä¸€ä¸ªå…ƒç´ : shape={item[0].shape}, device={item[0].device}\")\n",
    "    else:\n",
    "        print(f\" [{i}] å…¶ä»–ç±»å‹: {type(item)}\")\n",
    "\n",
    "# ==================== åˆ†æå‡½æ•° ====================\n",
    "def analyze_layer(layer_name, layer_config, mid_res):\n",
    "    \"\"\"åˆ†æå•ä¸ªå·ç§¯å±‚\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"åˆ†æ {layer_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    try:\n",
    "        layer_output = mid_res[layer_config['index']]\n",
    "        print(f\"åŸå§‹æ•°æ®ç±»å‹: {type(layer_output)}\")\n",
    "        if isinstance(layer_output, (list, tuple)):\n",
    "            print(f\" æ˜¯åºåˆ—ç±»å‹ï¼Œé•¿åº¦={len(layer_output)}\")\n",
    "            tensor = layer_output[0]\n",
    "        else:\n",
    "            tensor = layer_output\n",
    "        print(f\"Tensorç±»å‹: {type(tensor)}\")\n",
    "        print(f\"Tensorå½¢çŠ¶: {tensor.shape}\")\n",
    "        print(f\"Tensorè®¾å¤‡: {tensor.device}\")\n",
    "        print(f\"éœ€è¦æ¢¯åº¦: {tensor.requires_grad}\")\n",
    "        \n",
    "        print(\"æ­£åœ¨è½¬æ¢ä¸ºnumpy...\")\n",
    "        data = tensor_to_numpy(tensor)\n",
    "        print(f\"âœ… è½¬æ¢æˆåŠŸï¼numpyå½¢çŠ¶: {data.shape}\")\n",
    "        \n",
    "        print(f\"åŸå§‹å½¢çŠ¶: {data.shape}\")\n",
    "        while data.ndim > 2:\n",
    "            if 1 in data.shape:\n",
    "                data = np.squeeze(data)\n",
    "                print(f\" squeezeå: {data.shape}\")\n",
    "            else:\n",
    "                if data.shape[0] == 1:\n",
    "                    data = data[0]\n",
    "                    print(f\" å–ç¬¬ä¸€ä¸ªbatch: {data.shape}\")\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        if data.ndim == 3:\n",
    "            data = data.squeeze()\n",
    "            print(f\" æœ€ç»ˆsqueeze: {data.shape}\")\n",
    "        print(f\"âœ… æœ€ç»ˆå½¢çŠ¶: {data.shape}\")\n",
    "        \n",
    "        stride = layer_config['stride']\n",
    "        ltr_start = LTR_START_ORIG // stride\n",
    "        ltr_end = LTR_END_ORIG // stride\n",
    "        ltr_width = ltr_end - ltr_start\n",
    "        \n",
    "        print(f\"\\nç‰¹å¾å›¾å½¢çŠ¶: {data.shape}\")\n",
    "        print(f\"LTR-RTåŸå§‹ä½ç½®: {LTR_START_ORIG} - {LTR_END_ORIG} bp ({LTR_END_ORIG - LTR_START_ORIG} bp)\")\n",
    "        print(f\"LTR-RTç‰¹å¾ä½ç½®: {ltr_start} - {ltr_end} ({ltr_width} ä¸ªä½ç½®)\")\n",
    "        print(f\"åˆ†è¾¨ç‡: æ¯ä¸ªç‰¹å¾ä½ç½® â‰ˆ {stride} bp\")\n",
    "        \n",
    "        print(\"æ­£åœ¨å½’ä¸€åŒ–...\")\n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        data_norm = scaler.fit_transform(data.T).T\n",
    "        print(\"âœ… å½’ä¸€åŒ–å®Œæˆ\")\n",
    "        \n",
    "        print(\"è®¡ç®—é€‰æ‹©æ€§æŒ‡æ•°...\")\n",
    "        ltr_region = data[:, ltr_start:ltr_end]\n",
    "        bg_indices = list(range(0, ltr_start)) + list(range(ltr_end, data.shape[1]))\n",
    "        bg_region = data[:, bg_indices]\n",
    "        \n",
    "        ltr_activation = ltr_region.mean(axis=1)\n",
    "        bg_activation = bg_region.mean(axis=1)\n",
    "        selectivity = (ltr_activation - bg_activation) / (ltr_activation + bg_activation + 1e-8)\n",
    "        \n",
    "        ltr_selective = np.sum(selectivity > 0.2)\n",
    "        bg_selective = np.sum(selectivity < -0.2)\n",
    "        neutral = np.sum(np.abs(selectivity) <= 0.2)\n",
    "        \n",
    "        print(f\"\\né€‰æ‹©æ€§ç»Ÿè®¡:\")\n",
    "        print(f\" LTRç‰¹å¼‚æ€§é€šé“ (SI > 0.2): {ltr_selective} ({100*ltr_selective/len(selectivity):.1f}%)\")\n",
    "        print(f\" èƒŒæ™¯ç‰¹å¼‚æ€§é€šé“ (SI < -0.2): {bg_selective} ({100*bg_selective/len(selectivity):.1f}%)\")\n",
    "        print(f\" ä¸­æ€§é€šé“: {neutral} ({100*neutral/len(selectivity):.1f}%)\")\n",
    "        \n",
    "        top_ch = np.argsort(np.abs(selectivity))[-5:][::-1]\n",
    "        print(f\"\\nTop 5 åˆ¤åˆ«é€šé“:\")\n",
    "        for i, ch in enumerate(top_ch, 1):\n",
    "            print(f\" {i}. Channel {ch}: SI = {selectivity[ch]:+.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'data': data,\n",
    "            'data_norm': data_norm,\n",
    "            'ltr_start': ltr_start,\n",
    "            'ltr_end': ltr_end,\n",
    "            'selectivity': selectivity,\n",
    "            'top_channels': top_ch,\n",
    "            'stats': {\n",
    "                'ltr_selective': ltr_selective,\n",
    "                'bg_selective': bg_selective,\n",
    "                'neutral': neutral\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ é”™è¯¯: {e}\")\n",
    "        print(f\"é”™è¯¯ç±»å‹: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ==================== åˆ†ææ‰€æœ‰å±‚ ====================\n",
    "results = {}\n",
    "for layer_name, config in LAYER_CONFIG.items():\n",
    "    result = analyze_layer(layer_name, config, mid_res)\n",
    "    if result is not None:\n",
    "        results[layer_name] = result\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ {layer_name} åˆ†æå¤±è´¥ï¼Œè·³è¿‡\")\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"\\nâŒ æ‰€æœ‰å±‚éƒ½åˆ†æå¤±è´¥ï¼\")\n",
    "    print(\"è¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œç´¢å¼•æ˜¯å¦æ­£ç¡®\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\nâœ… æˆåŠŸåˆ†æäº† {len(results)} ä¸ªå±‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ç”Ÿæˆå¸¦ LTR-RT åŒºé—´é«˜äº®çš„çƒ­å›¾...\n",
      "============================================================\n",
      "\n",
      "âœ… Conv1 é«˜äº®çƒ­å›¾å·²ä¿å­˜: Conv1_heatmap_highlighted.png\n",
      " - å›¾ç‰‡å°ºå¯¸: 12Ã—10 inches\n",
      " - ç‰¹å¾å›¾: 32 channels Ã— 49981 positions\n",
      " - LTR-RT: [20497, 29484] (8987 pos)\n",
      "\n",
      "âœ… Conv2 é«˜äº®çƒ­å›¾å·²ä¿å­˜: Conv2_heatmap_highlighted.png\n",
      " - å›¾ç‰‡å°ºå¯¸: 12Ã—10 inches\n",
      " - ç‰¹å¾å›¾: 64 channels Ã— 4979 positions\n",
      " - LTR-RT: [2050, 2929] (879 pos)\n",
      "\n",
      "âœ… Conv3 é«˜äº®çƒ­å›¾å·²ä¿å­˜: Conv3_heatmap_highlighted.png\n",
      " - å›¾ç‰‡å°ºå¯¸: 12Ã—10 inches\n",
      " - ç‰¹å¾å›¾: 128 channels Ã— 297 positions\n",
      " - LTR-RT: [137, 160] (23 pos)\n",
      "\n",
      "============================================================\n",
      "âœ… å®Œæˆï¼æ‰€æœ‰å¸¦é«˜äº®çš„çƒ­å›¾å·²ç”Ÿæˆ\n",
      "============================================================\n",
      "\n",
      "å›¾ä¾‹è¯´æ˜:\n",
      "  ğŸ”´ çº¢è‰²å®çº¿æ¡†: All-LTR-RT åŒºé—´ (å·ç§¯æ ¸å®Œå…¨åœ¨LTR-RTå†…)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== ç”Ÿæˆå¸¦é«˜äº®çš„çƒ­å›¾ ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ç”Ÿæˆå¸¦ LTR-RT åŒºé—´é«˜äº®çš„çƒ­å›¾...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for layer_name, result in results.items():\n",
    "    data_width = result['data'].shape[1]\n",
    "    data_channels = result['data'].shape[0]\n",
    "    \n",
    "    fig_width = 12  # åŠ å®½ä»¥å®¹çº³å›¾ä¾‹\n",
    "    fig_height = 10\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # ç»˜åˆ¶çƒ­å›¾\n",
    "    im = ax.imshow(result['data_norm'], aspect='auto', cmap='RdYlBu_r',\n",
    "                   interpolation='nearest', vmin=-2, vmax=2)\n",
    "    \n",
    "    # LTR-RT åŒºé—´é«˜äº®\n",
    "    if layer_name in LTR_INTERVALS:\n",
    "        intervals = LTR_INTERVALS[layer_name]\n",
    "        \n",
    "        # 1. ç»˜åˆ¶ LTR-RT åŒºé—´ï¼ˆç»¿è‰²å®çº¿æ¡†ï¼‰\n",
    "        all_start, all_end = intervals['all_ltr']\n",
    "        all_width = all_end - all_start\n",
    "        \n",
    "        all_rect = patches.Rectangle(\n",
    "            (all_start - 0.5, -0.5),\n",
    "            all_width,\n",
    "            data_channels,\n",
    "            linewidth=2.5,\n",
    "            edgecolor='limegreen',\n",
    "            facecolor='none',\n",
    "            linestyle='-',\n",
    "            label='LTR-RT',\n",
    "            zorder=10\n",
    "        )\n",
    "        ax.add_patch(all_rect)\n",
    "    \n",
    "    # è®¡ç®—å±‚æè¿°\n",
    "    if layer_name == 'Conv1':\n",
    "        layer_desc = 'Conv1'\n",
    "    elif layer_name == 'Conv2':\n",
    "        layer_desc = 'Conv2'\n",
    "    else:\n",
    "        layer_desc = 'Conv3'\n",
    "    \n",
    "    # æ ‡é¢˜\n",
    "    ax.set_title(f\"{layer_desc} with LTR-RT Regions\\n\"\n",
    "                 f\"Shape: {data_channels} channels Ã— {data_width} positions\",\n",
    "                 fontsize=30, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel('Feature Map Position', fontsize=25)\n",
    "    ax.set_ylabel('Channel', fontsize=25)\n",
    "    ax.tick_params(axis='both', labelsize=25)\n",
    "    # é¢œè‰²æ¡\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Normalized Activation', rotation=270, labelpad=20, fontsize=25)\n",
    "    \n",
    "    # æ·»åŠ å›¾ä¾‹\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        by_label = dict(zip(labels, handles))  # å»é‡\n",
    "        ax.legend(by_label.values(), by_label.keys(), \n",
    "                 loc='upper right', fontsize=25, framealpha=0.9)\n",
    "    \n",
    "    # ç½‘æ ¼\n",
    "    if data_channels <= 64:\n",
    "        ytick_step = max(1, data_channels // 16)\n",
    "    else:\n",
    "        ytick_step = max(1, data_channels // 20)\n",
    "    ax.set_yticks(np.arange(0, data_channels, ytick_step))\n",
    "    ax.grid(True, alpha=0.2, axis='y', linestyle=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    filename = f'{layer_name}_heatmap_highlighted.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ… {layer_name} é«˜äº®çƒ­å›¾å·²ä¿å­˜: {filename}\")\n",
    "    print(f\" - å›¾ç‰‡å°ºå¯¸: {fig_width}Ã—{fig_height} inches\")\n",
    "    print(f\" - ç‰¹å¾å›¾: {data_channels} channels Ã— {data_width} positions\")\n",
    "    \n",
    "    # æ‰“å°åŒºé—´ä¿¡æ¯\n",
    "    if layer_name in LTR_INTERVALS:\n",
    "        intervals = LTR_INTERVALS[layer_name]\n",
    "        all_start, all_end = intervals['all_ltr']\n",
    "        print(f\" - LTR-RT: [{all_start}, {all_end}] ({all_end-all_start} pos)\")\n",
    "    \n",
    "    print()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"âœ… å®Œæˆï¼æ‰€æœ‰å¸¦é«˜äº®çš„çƒ­å›¾å·²ç”Ÿæˆ\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nå›¾ä¾‹è¯´æ˜:\")\n",
    "print(\"  ğŸ”´ çº¢è‰²å®çº¿æ¡†: LTR-RT åŒºé—´ (LTR-RTå®Œå…¨åœ¨å·ç§¯æ ¸å†…)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
