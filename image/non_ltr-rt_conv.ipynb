{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da9a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/ipykernel_815437/3689549940.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\", line 870, in <module>\n",
      "    from . import _masked\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py\", line 420, in <module>\n",
      "    def sum(input: Tensor,\n",
      "  File \"/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py\", line 223, in _apply_docstring_templates\n",
      "    example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n",
      "/proj/nobackup/hpc2nstor2024-028/zhychen/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_masked/__init__.py:223: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载non-LTR-RT数据...\n",
      "\n",
      "mid_res类型: <class 'list'>\n",
      "mid_res长度: 17\n",
      "\n",
      "前几个元素的信息:\n",
      "  [0] Tensor: shape=torch.Size([1, 1, 5, 50000]), device=cpu\n",
      "  [1] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      "  [2] Tensor: shape=torch.Size([1, 32, 1, 49981]), device=cpu\n",
      "  [3] Tensor: shape=torch.Size([1, 32, 1, 4998]), device=cpu\n",
      "  [4] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      "  [5] Tensor: shape=torch.Size([1, 64, 1, 4979]), device=cpu\n",
      "  [6] Tensor: shape=torch.Size([1, 64, 1, 331]), device=cpu\n",
      "  [7] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      "  [8] Tensor: shape=torch.Size([1, 128, 1, 297]), device=cpu\n",
      "  [9] Tensor: shape=torch.Size([1, 128, 1, 19]), device=cpu\n",
      "\n",
      "============================================================\n",
      "分析 Conv1\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 32, 1, 49981])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 32, 1, 49981)\n",
      "原始形状: (1, 32, 1, 49981)\n",
      "  squeeze后: (32, 49981)\n",
      "✅ 最终形状: (32, 49981)\n",
      "\n",
      "特征图形状: (32, 49981)\n",
      "分辨率: 每个特征位置 ≈ 10 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "\n",
      "激活统计:\n",
      "  均值: -0.4572\n",
      "  标准差: 0.9180\n",
      "  最小值: -5.7449\n",
      "  最大值: 4.5348\n",
      "\n",
      "============================================================\n",
      "分析 Conv2\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 64, 1, 4979])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 64, 1, 4979)\n",
      "原始形状: (1, 64, 1, 4979)\n",
      "  squeeze后: (64, 4979)\n",
      "✅ 最终形状: (64, 4979)\n",
      "\n",
      "特征图形状: (64, 4979)\n",
      "分辨率: 每个特征位置 ≈ 150 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "\n",
      "激活统计:\n",
      "  均值: 0.5966\n",
      "  标准差: 2.2552\n",
      "  最小值: -11.3152\n",
      "  最大值: 13.3811\n",
      "\n",
      "============================================================\n",
      "分析 Conv3\n",
      "============================================================\n",
      "原始数据类型: <class 'torch.Tensor'>\n",
      "Tensor类型: <class 'torch.Tensor'>\n",
      "Tensor形状: torch.Size([1, 128, 1, 297])\n",
      "Tensor设备: cpu\n",
      "需要梯度: False\n",
      "正在转换为numpy...\n",
      "✅ 转换成功！numpy形状: (1, 128, 1, 297)\n",
      "原始形状: (1, 128, 1, 297)\n",
      "  squeeze后: (128, 297)\n",
      "✅ 最终形状: (128, 297)\n",
      "\n",
      "特征图形状: (128, 297)\n",
      "分辨率: 每个特征位置 ≈ 2250 bp\n",
      "正在归一化...\n",
      "✅ 归一化完成\n",
      "\n",
      "激活统计:\n",
      "  均值: -11.0425\n",
      "  标准差: 13.2898\n",
      "  最小值: -102.2792\n",
      "  最大值: 8.1250\n",
      "\n",
      "✅ 成功分析了 3 个层\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "分析non-LTR-RT数据的所有卷积层 (Conv1, Conv2, Conv3)\n",
    "生成与LTR-RT数据一致风格的热图用于对比\n",
    "不进行特定区域的选择性分析，仅展示整体特征分布\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"\n",
    "    使用tolist()方法安全转换tensor到numpy\n",
    "    这是最可靠的方法\n",
    "    \"\"\"\n",
    "    # 如果已经是numpy数组，直接返回\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        return tensor\n",
    "    # 如果是Python列表，转为numpy\n",
    "    if isinstance(tensor, (list, tuple)):\n",
    "        return np.array(tensor)\n",
    "    # 处理PyTorch tensor - 使用tolist()方法\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        # 先detach和cpu（如果需要）\n",
    "        if tensor.requires_grad:\n",
    "            tensor = tensor.detach()\n",
    "        if tensor.is_cuda:\n",
    "            tensor = tensor.cpu()\n",
    "        # 使用tolist()转为Python列表，再转numpy\n",
    "        return np.array(tensor.tolist())\n",
    "    # 其他情况\n",
    "    return np.array(tensor)\n",
    "\n",
    "# ==================== 配置 ====================\n",
    "# 各层的映射参数（与原脚本保持一致）\n",
    "LAYER_CONFIG = {\n",
    "    'Conv1': {\n",
    "        'index': 1,\n",
    "        'stride': 10,\n",
    "        'channels': 32,\n",
    "        'name': 'Conv1 (after MaxPool 10x)'\n",
    "    },\n",
    "    'Conv2': {\n",
    "        'index': 4,\n",
    "        'stride': 150,  # 10 * 15\n",
    "        'channels': 64,\n",
    "        'name': 'Conv2 (after MaxPool 150x)'\n",
    "    },\n",
    "    'Conv3': {\n",
    "        'index': 7,\n",
    "        'stride': 2250,  # 10 * 15 * 15\n",
    "        'channels': 128,\n",
    "        'name': 'Conv3 (after MaxPool 2250x)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================== 加载数据 ====================\n",
    "print(\"加载non-LTR-RT数据...\")\n",
    "mid_res = torch.load('non-LTR_RTtensor_data.pt')\n",
    "\n",
    "# 检查数据结构\n",
    "print(f\"\\nmid_res类型: {type(mid_res)}\")\n",
    "print(f\"mid_res长度: {len(mid_res)}\")\n",
    "print(\"\\n前几个元素的信息:\")\n",
    "for i in range(min(10, len(mid_res))):\n",
    "    item = mid_res[i]\n",
    "    if isinstance(item, torch.Tensor):\n",
    "        print(f\"  [{i}] Tensor: shape={item.shape}, device={item.device}\")\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        print(f\"  [{i}] List/Tuple: 长度={len(item)}\")\n",
    "        if len(item) > 0 and isinstance(item[0], torch.Tensor):\n",
    "            print(f\"       第一个元素: shape={item[0].shape}, device={item[0].device}\")\n",
    "    else:\n",
    "        print(f\"  [{i}] 其他类型: {type(item)}\")\n",
    "\n",
    "# ==================== 分析函数 ====================\n",
    "def analyze_layer(layer_name, layer_config, mid_res):\n",
    "    \"\"\"分析单个卷积层\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"分析 {layer_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # 提取数据 - 处理可能的嵌套结构\n",
    "        layer_output = mid_res[layer_config['index']]\n",
    "        print(f\"原始数据类型: {type(layer_output)}\")\n",
    "        \n",
    "        # 如果是列表或元组，取第一个元素\n",
    "        if isinstance(layer_output, (list, tuple)):\n",
    "            print(f\"  是序列类型，长度={len(layer_output)}\")\n",
    "            tensor = layer_output[0]\n",
    "        else:\n",
    "            tensor = layer_output\n",
    "        \n",
    "        print(f\"Tensor类型: {type(tensor)}\")\n",
    "        print(f\"Tensor形状: {tensor.shape}\")\n",
    "        print(f\"Tensor设备: {tensor.device}\")\n",
    "        print(f\"需要梯度: {tensor.requires_grad}\")\n",
    "        \n",
    "        # 转换为numpy\n",
    "        print(\"正在转换为numpy...\")\n",
    "        data = tensor_to_numpy(tensor)\n",
    "        print(f\"✅ 转换成功！numpy形状: {data.shape}\")\n",
    "        \n",
    "        # 关键：去除多余的维度 (1, 32, 1, 49981) -> (32, 49981)\n",
    "        print(f\"原始形状: {data.shape}\")\n",
    "        while data.ndim > 2:\n",
    "            # 找到大小为1的维度并squeeze\n",
    "            if 1 in data.shape:\n",
    "                data = np.squeeze(data)\n",
    "                print(f\"  squeeze后: {data.shape}\")\n",
    "            else:\n",
    "                # 如果没有大小为1的维度，可能需要reshape\n",
    "                # 假设格式是 (batch, channels, height, width)\n",
    "                # 取第一个batch\n",
    "                if data.shape[0] == 1:\n",
    "                    data = data[0]\n",
    "                    print(f\"  取第一个batch: {data.shape}\")\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        # 确保是2D (channels, positions)\n",
    "        if data.ndim == 3:\n",
    "            # 如果还是3D，可能是 (channels, 1, positions)\n",
    "            data = data.squeeze()\n",
    "            print(f\"  最终squeeze: {data.shape}\")\n",
    "        \n",
    "        print(f\"✅ 最终形状: {data.shape}\")\n",
    "        \n",
    "        stride = layer_config['stride']\n",
    "        \n",
    "        print(f\"\\n特征图形状: {data.shape}\")\n",
    "        print(f\"分辨率: 每个特征位置 ≈ {stride} bp\")\n",
    "        \n",
    "        # 归一化（使用与原脚本相同的方法）\n",
    "        print(\"正在归一化...\")\n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        data_norm = scaler.fit_transform(data.T).T\n",
    "        print(\"✅ 归一化完成\")\n",
    "        \n",
    "        # 计算基本统计信息\n",
    "        print(f\"\\n激活统计:\")\n",
    "        print(f\"  均值: {data.mean():.4f}\")\n",
    "        print(f\"  标准差: {data.std():.4f}\")\n",
    "        print(f\"  最小值: {data.min():.4f}\")\n",
    "        print(f\"  最大值: {data.max():.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'data': data,\n",
    "            'data_norm': data_norm,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 错误: {e}\")\n",
    "        print(f\"错误类型: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ==================== 分析所有层 ====================\n",
    "results = {}\n",
    "for layer_name, config in LAYER_CONFIG.items():\n",
    "    result = analyze_layer(layer_name, config, mid_res)\n",
    "    if result is not None:\n",
    "        results[layer_name] = result\n",
    "    else:\n",
    "        print(f\"\\n⚠️ {layer_name} 分析失败，跳过\")\n",
    "\n",
    "# 检查是否有成功的结果\n",
    "if len(results) == 0:\n",
    "    print(\"\\n❌ 所有层都分析失败！\")\n",
    "    print(\"请检查数据格式和索引是否正确\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\n✅ 成功分析了 {len(results)} 个层\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb57b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "生成non-LTR-RT纯净热图...\n",
      "============================================================\n",
      "\n",
      "✅ Conv1 non-LTR-RT热图已保存: Conv1_non-LTR_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 32 channels × 49981 positions\n",
      "\n",
      "✅ Conv2 non-LTR-RT热图已保存: Conv2_non-LTR_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 64 channels × 4979 positions\n",
      "\n",
      "✅ Conv3 non-LTR-RT热图已保存: Conv3_non-LTR_heatmap_clean.png\n",
      "   - 图片尺寸: 12×10 inches\n",
      "   - 特征图: 128 channels × 297 positions\n",
      "\n",
      "============================================================\n",
      "✅ 完成！所有non-LTR-RT热图已生成\n",
      "============================================================\n",
      "\n",
      "生成的文件:\n",
      "  - Conv1_non-LTR_heatmap_clean.png\n",
      "  - Conv2_non-LTR_heatmap_clean.png\n",
      "  - Conv3_non-LTR_heatmap_clean.png\n"
     ]
    }
   ],
   "source": [
    "# ==================== 生成无标亮的纯净热图 ====================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"生成non-LTR-RT纯净热图...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for layer_name, result in results.items():\n",
    "    data_width = result['data'].shape[1]\n",
    "    data_channels = result['data'].shape[0]\n",
    "    \n",
    "    # 统一图片尺寸 - 所有图都方正（与原脚本完全一致）\n",
    "    fig_width = 12\n",
    "    fig_height = 10\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # 绘制热图（使用与原脚本完全相同的参数）\n",
    "    im = ax.imshow(result['data_norm'], aspect='auto', cmap='RdYlBu_r',\n",
    "                   interpolation='nearest', vmin=-2, vmax=2)\n",
    "    \n",
    "    # 计算层描述\n",
    "    if layer_name == 'Conv1':\n",
    "        layer_desc = 'Conv1'\n",
    "    elif layer_name == 'Conv2':\n",
    "        layer_desc = 'Conv2'\n",
    "    else:\n",
    "        layer_desc = 'Conv3'\n",
    "    \n",
    "    # 标题 - 标注为non-LTR-RT数据\n",
    "    ax.set_title(f\"{layer_desc} without LTR-RT Regions\\n\"\n",
    "                 f\"Shape: {data_channels} channels × {data_width} positions\",\n",
    "                 fontsize=30, fontweight='bold', pad=15)\n",
    "    \n",
    "    ax.set_xlabel('Feature Map Position', fontsize=25)\n",
    "    ax.set_ylabel('Channel', fontsize=25)\n",
    "    ax.tick_params(axis='both', labelsize=25)\n",
    "    # 颜色条（与原脚本完全一致）\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Normalized Activation', rotation=270, labelpad=20, fontsize=25)\n",
    "    \n",
    "    # 网格 - 根据通道数调整（与原脚本完全一致）\n",
    "    if data_channels <= 64:\n",
    "        ytick_step = max(1, data_channels // 16)\n",
    "    else:\n",
    "        ytick_step = max(1, data_channels // 20)\n",
    "    \n",
    "    ax.set_yticks(np.arange(0, data_channels, ytick_step))\n",
    "    ax.grid(True, alpha=0.2, axis='y', linestyle=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存 - 文件名标注non-LTR\n",
    "    filename = f'{layer_name}_non-LTR_heatmap_clean.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ {layer_name} non-LTR-RT热图已保存: {filename}\")\n",
    "    print(f\"   - 图片尺寸: {fig_width}×{fig_height} inches\")\n",
    "    print(f\"   - 特征图: {data_channels} channels × {data_width} positions\\n\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"✅ 完成！所有non-LTR-RT热图已生成\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "print(\"生成的文件:\")\n",
    "for layer_name in results.keys():\n",
    "    print(f\"  - {layer_name}_non-LTR_heatmap_clean.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
